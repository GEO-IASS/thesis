% !TEX root = ../main.tex
% Appendix A

\chapter{Summaries} % Main appendix title

\label{AppendixA} % For referencing this appendix elsewhere, use \ref{AppendixA}

\lhead{Appendix A. \emph{Summaries}} % This is for the header on each page - perhaps a shortened title

Please ignore this Appendix.
This appendix is for my own personal use.
It contains summaries of articles I have read.

%----------------------------------------------------------------------------------------
\section{Support Vector Machines}

\subsection{Machine learning: the art and science of algorithms that make sense of data}
Book by Peter Flach: \cite{flach2012machine}.
Mainly about chapter 7, ``Linear Models''.
Most important: section 7.3 - 7.5, about support vector machines and non-linearity.
\textbf{Some parts are direct text; do not use this text directly!}

\subsection{Linear models}
Models can be represented by their geometry of $d$ real-values features.
Data points are represented in the $d$-dimensional cartesian coordinate system/space $\mathcal{X} = \mathbb{R}^d$.
Geometric concepts such as lines and planes can be used for \emph{classification} and \emph{regression}.
An alternative approach is to use the distance between datapoints as a similarity measure, resulting from the geometrical representation.
Linear methods do not use that property, but rely on understanding of models in terms of lines and planes.

Linear models are of great interest in machine learning because of their simplicity.
A few manifestations of this simplicity are:
\begin{itemize}
  \item Linear models are \emph{parametric}, thus fixed small number of parameters that need to be learned from the data.
  \item Linear models are \emph{stable}, thus small variations in training data have small impact on the learned model. In logical models they can have large impact, because ``splitting rules'' in root have great impact.
  \item Due to relative few parameters, less likely to \emph{overfit} the training data.
\end{itemize}

The last two are summarized by saying that \emph{linear models have low variance but high bias}.
This is preferred with limited data and overfitting is to be avoided.

Linear models are well studied, in particular for the problem of linear regression.
This can be solved by the \emph{least-squares} method and classification as discussed in section \ref{least-squares}, the \emph{perceptron} as explained in section \ref{perceptron}.
Linear regression with the \emph{support vector machine} is handled in section \ref{svm-explained} and used for probability density estimation in section \ref{svm-pdf}.
The kernel trick used for learning non-linear models is explained in section \ref{non-linear}.

\subsection{Least-squares method}\label{least-squares}
The regression problem is to learn a function estimator $\hat{f}:\mathcal{X} \to \mathbb{R}$ from the examples $(x_i, f(x_i))$ where we assume $\mathcal{X} = \mathbb{R}^d$.
The difference between the actual and estimated function values are called \emph{residuals} $\epsilon_i = f(x_i) - \hat{f}(x_i)$.
The \emph{least-squares method} finds the estimation $\hat{f}$ by minimizing $\sum_{i=1}^{n} \epsilon_i^2$.
Univariate regressesion assumes a linear equation $y = a + b x$, with parameters $a$ and $b$ chosen such that the sum of squared residuals $\sum_{i=1}^{n} (y_i - (a + b x_i))^2$ is minimized.
Here the estimated parameter $\hat{a}$ is called the \emph{intercept} such that it goes through the (estimated) pooint $(\hat{x},\hat{y})$ and $\hat{b}$is the \emph{slope} which can be expressed by the (co)variances: $\hat{b} = \frac{\sigma_{xy}}{\sigma_{xx}}$.
In order to find the parameters, take the partial derivatives, set them to $0$ and solve for $a$ and $b$.

Although least-squares is sensitive to outliers, it works very well for such a simple method.
This can be explained as folows.
We can assume the underlying function is indeed linear but contanimated with random noise.
That means that our examples are actually $(x_i, f(x_i) + \epsilon_i)$ and $f(x) = ax + b$.
If we know $a$ and $b$ we can calculate what the residuals are, and by knowing $\sigma^2$ we can estimate \emph{the probability of observering the residuals}.
But since we don't know $a$ and $b$ we have to estimate them, by estimating the values for $a$ and $b$ that maximizes the probability of the residuals.
This is the \emph{maximum-likelihood estimate} (chapter 9 in the book).

The least-squares method can be used for a (binary) classifier, by encoding the target variable $y$ as classes by real numbers $-1$ (negative) and $1$ (positive).
It follows that $\matrixsym{X}^T\vectorsym(y) = P \vectorsym{\mu^+} - N \vectorsym{\mu^-}$, where $P$, $N$, $\vectorsym{\mu^+}$ and $\vectorsym{\mu^-}$ are the number of positive and negative examples, and the $d$-vectors containing each feature's mean values, resp.
The regression equation $y = \bar{y} + \hat{b}(x - \bar{x})$ can be used to obtain a decision boundary.
We need to determine the point $(x_0, y_0)$ such that $y_0$ is half-way between $y^+$ and $y^-$ (the positive and negative examples, i.e. $y_0 = 0$).

\subsection{Perceptron}\label{perceptron}
Labelled data is \emph{linearly separable} if the exists a linear boundary separating the classes.
The least-squares may find one, but it is not guaranteed.
Image a perfect linearly separatable data set.
Move all the positive points away from the negative, but one.
At one point the new boundary will exclude (misqualify) the one original positive outlier, due to the mean-statistics it relies on.
The \emph{perceptron} will guaranteed perform perfect separation when the data allows it to be.
It was originally proposed as a \emph{simple neural network}.
It works by iterating over the training set and modifying the weight vector for every misclassified example ($\vectorsym{w} \cdot \vectorsym{x}_i < t$ for positive examples $\vectorsym{x}_i$).
It uses a learning rate $\eta$, for a misclassified $y_i = \left\{-1,+1\right\}$: $\vectorsym{w}' = \vectorsym{w} + \eta y_i \vectorsym{x}_i$.
The algorithm can be made \emph{online} by processing a stream of data points and and updating the weight vector only when a new data point is misclassified.

When the algorithm is completed, every $y_i\vectorsym{x}_i$ is added $\alpha_i$ times to the weight vector (every time it was misclassified).
Thus, the weight vector can be expressed as: $\vectorsym{w} = \sum_{i=i}^n \alpha_i y_i \vectorsym{x}_i$.
In other words: the weight vector is a linear combination of the training instances.
The dual form of the algorithm learns the instance weights $\alpha_i$ rather than the features weights $\vectorsym{w}_i$.
An instance $\vectorsym{x}$ is then classified as $\hat{y} = sign(\sum_{i=1}^n \alpha_i y_i \vectorsym{x}_i \cdot \vectorsym{x})$.
This means that during the training only the pairwise dot-products of the data is needed; this results in the \emph{n}-by-\emph{n} Gram matrix $\matrixsym{G} = \matrixsym{X}\matrixsym{X}^T$.
This instance-based perspective will be further discussed in section \ref{svm-explained} about the support vector machine.

\subsection{Support Vector Machine}\label{svm-explained}
\subsection{Support Vector Machine Density Functions}\label{svm-pdf}
\subsection{Non-linear models}\label{non-linear}


%----------------------------------------------------------------------------------------