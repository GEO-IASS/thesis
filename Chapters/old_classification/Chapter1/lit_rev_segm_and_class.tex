% Section Signal Pre-processing
% !TEX root = ../../main.tex

\subsection{Segmentation and classification}\label{sec:lit_review_segmentation}
In recent years much research is done in the field of segmentation and classification of signals into human activities.
Due to the nature of many applied algorithms and the field of research (computer vision, data mining, robotics), often there is no clear distinction between the segmentation and classification phase.
As a result, these two subjects will be discussed together although, where possible, the different techniques for the two will be mentioned.
All the reviewed papers have a global setup in common; a single- or multiple- sensory device is worn by subjects.
From the raw signals features are extracted which are used to train some models.
During the testing phase the same extracted features are compared with the trained models to classify the activity.
Some methods rely on clear segmentations of the signals, whilst other ignore this possible feature and classify on sliding windows.
The content of this section is summarized in table \ref{table:papers_segmentation_classification}.

During the last ten years much research is performed, as a result of smaller and cheaper measuring devices. \TODO{cite needed}.
With the introduction of smartphones with sensory hardware the research has shifted to these devices, as they create a more natural and ubiquitous setting for the test subject. \TODO{cite needed}.

A distinction can be made in the sensor setup, like wearing multiple sensors, a single sensor and the location of the sensors.
Research have been performed with multiple sensors, refered to as Body Sensor Networks, as done in \cite{guenterberg2009automatic, guenterberg2009distributed, bao2004activity, sherril2005using}.
Locations used include the upper arm, waist, thigh, wrist and ankle.
Single sensors have be worn at different locations, including the upper arm \cite{krause2003unsupervised}, the front leg pocket \cite{kwapisz2011activity, duque2012offline, siirtola2012recognizing, he2009activity}, the waist \cite{ravi2005activity, lester2006practical, lee2178physical}, the chest \cite{ahmed2012non, himberg2001time}, the shoulder \cite{lester2005hybrid} and the dominant wrist \cite{yang2008using, long2009single}.
Other approaches have not used body-worn sensors at all, but instead relied on other meaures, such as motion capture data \cite{barbivc2004segmenting, zhou2008aligned} and visual \cite{perdikis2008recognition} and acoustic data in office surroundings \cite{oliver2002layered}

In \cite{bao2004activity} the effectiveness of different body locations for sensors is discussed.
It is shown that using two locations (the hip and wrist or thigh and wrist) instead of five does not significantly reduce the activity recognition.
The (dominant) wrist is the preferred location when only a single sensor is used.

Some experiments have only been performed in an artificial or laboratory setting \cite{minnen2006discovering, yang2008using, perdikis2008recognition, guenterberg2009automatic, ravi2005activity, bao2004activity, sherril2005using, he2009activity}, thus probably resulting in less robust trained models.
In \cite{siirtola2012recognizing, kwapisz2011activity} the experiments are performed in a uncontrolled environment.
This results in a more natural setting with more noise due to free movement.
It also introduces transition-states in the data, because there is no clear distinction between activities.
The method of \cite{krause2003unsupervised} explicitly filters the signals for transitions.
Others have provided the test subjects with a measuring device for a longer period of time, some up to a few days \cite{krause2003unsupervised, long2009single}.

A more objective comparison can be made based on the segmentation and classification technique used.
In \cite{bao2004activity} and \cite{ravi2005activity} extensive comparisons are made between much used algorithms which are widely implemented, such as in the WEKA toolkit \cite{hall2009weka}.
These include the base-classifiers Decision Trees (also used in \cite{kwapisz2011activity,duque2012offline}), Decision Tables, K-nearest neighbors (also used \cite{duque2012offline, siirtola2012recognizing}), Support Vector Machines (also used in \cite{derawi2010accelerometer,he2009activity, he2008activity}) and Naive Bayes (also used in \cite{long2009single}).
The research of \cite{bao2004activity} also implemented a number of meta-level classifiers, of which Plurality Voting resulted in the highest accuracy.
A very well known and applied algorithm from the field of data mining is $k$-means clustering.
A drawback of this method is that the number of expected clusters needs to be predetermined.
To overcome this shortcoming an iterative implementation can be used, which selects the best clustering.
A variant is known as Fuzzy $c$-means clustering, in which a data point can belong to one or more clusters, each with a degree of membership.
The method of $k$-means clustering (or a modified version) is used in \cite{krause2003unsupervised, zhou2008aligned, lee2178physical}.

Very much used in machine learning problems are neural networks. \TODO{cite needed}
Although these kind of networks typically perform well on spatial-typed problems \TODO{cite needed}, adjustments have been made to apply them for temporal classification.
The methods of \cite{yang2008using, kwapisz2011activity} create a multi-level neural network to generate complex discriminators as activity classifiers.
A variant of neural networks known as Kohonen Self Organizing Maps is used in \cite{krause2003unsupervised} to create a vector codebook, which is further processed by a $k$-means clustering.

Due similarity with the problem of continuous speech recognition, Hidden Markov Models have been applied to activity recognition tasks.
A layered approach proved to be robust for small changes in \cite{perdikis2008recognition}.
In \cite{shi2009towards} five activities have been modeled as HMMs.
The method of \cite{fox2010bayesian} introduces HMMs with Markov Jump Linear Systems to segment a signal, with a fixed number of models.
In \cite{lester2006practical} a layer of HMMs of on top of a layer of static classifiers to estimate the current activity.
This has a commonality with \cite{lester2005hybrid} in which HMMs are used to capture regularities and smooth activity transitions.
The application of \cite{guenterberg2009distributed} constructs separate HHMs for each activity and then joins them in a single model to estimate the likelihood of an activity.

A common property of the above mentioned classification algorithms is that there is no explicit segmentation phase.
Data points can be segmented a posteriori, by joining adjacent data points which have the same label.
An approach in which the data points are processed per segment include \cite{minnen2006discovering}, in which motifs over sensor data from actions are discovered.
In \cite{guenterberg2009automatic} the signal is segmented (without classification) by applying adaptive threshold values on the energy of the signal.
The estimates of the direct density-ratio for probability distributions are compared to create change-points in \cite{kawahara2009change}.
By making minimal model assumptions a non-parametric segmentation is obtained, without classification.
A further application of probability distributions is discussed in \cite{ahmed2012non}, which uses an non-parametric Bayesian method to create an Infinite Gaussian Mixture Model to represent activities.
Very interesting is the ability to recognize past and new activities without training.
The method of \cite{barbivc2004segmenting} considers the intrinsic dimensionality of poses by using Probabilistic Principal Component Analysis and creates cut-points.
This method also is independent of trained models and thus also is a non-parametric approach.
The method of \cite{keogh2001online} creates a piecewise linear representation of the signal as thus approximates it.
This does not result in a segmentation in the sense of some homogeneity over the data points, but it can support one.
In contrast, the method of \cite{himberg2001time} splits and merges segments the signal in a constant number $k$ segments using a cost function to minimize the heterogeneity of a segment.

Each research outcome is defined in some kind of correctness to segment and classify the signal in the correct and preferred manner.
In many methods an error was measured as the difference between the algorithms outcome and a domain-experts ground truth.
In case of segmenting the time series, the method of \cite{guenterberg2009automatic} measures the delayed number of seconds before a new segment is created.
For classification the measure takes on many forms and names, such as recognition rates \cite{bao2004activity} or hit precision \cite{ahmed2012non}.
Confusion matrices often are used to give insight in which activities are hard to discriminate from each other, as for instance in \cite{kwapisz2011activity}.
The term false alarm rate is often used to indicate incorrectly new introduced elements, such as activities in \cite{ahmed2012non} and \cite{kawahara2009change}.

The overall results of many methods are fairly high and promising.
Many methods, for a fixed number of activities or an iterative approach, obtain precision up to the range from 95\% to 100\% \cite{minnen2006discovering, shi2009towards, kwapisz2011activity, duque2012offline, he2009activity, lee2178physical, siirtola2012recognizing}.
Problems for which the number of activities is unknown perform up to 95\% \cite{ahmed2012non, barbivc2004segmenting}.
The most problems arise from discriminating between similar activities, such as taking the stairs up or down and walking when the movement of legs or waist is considered \cite{kwapisz2011activity, duque2012offline}.

Some researchers have made their used data set explicitly public available and other data sets are just available, providing valuable labeled activity patterns. \TODO{This should be in experiments setup?}
\TODO{List here the datasets used}

\begin{table}
\tiny
\centering
\begin{tabular}{ | l | c | p{1.5cm} | p{1.5cm} | p{1.5cm} | p{2.5cm} | p{3cm} | }
  \hline
  Refs. & \# & Location & Activities & Env. & Algorithms & Results \\
  \hline
  \cite{minnen2006discovering} & Single & Wrist & Signal motifs & Artificial data & Motif discovery, HHMs, DTW & overall 87\% \\
  \hline
  \cite{guenterberg2009automatic} & Multiple & wrist, legs, waist & 12 daily routine & Controlled & Adaptive threshold, segmenting & 85\% \\
  \hline
  \cite{shi2009towards} & Single & Unknown & walking, upstairs, falling, running, standing & Controlled & FFT, HMMs & 90\% - 100\% \\
  \hline
  \cite{kawahara2009change} & - & - & - & Artificial data & Non-parametric Density-Ratio estimation & ??? \\
  \hline
  many more... & & & & & & \\
  \hline
\end{tabular}
\caption{Overview of researches with the focus on segmentation and classification techniques.}
\label{table:papers_segmentation_classification}
\end{table}