% Section Signal Pre-processing
% !TEX root = ../../main.tex

% \section{Literature review}
% Look into earlier application mentioned in the literature to this kind of  problems. Look for similarities in the problem and address where the  techniques used fail or are not applicable.

% *** Most of the activity recognition techniques can be classified in two  different types.
% Some rely on a state-space model, in which the activities to be recognized are represented in a statistical manner.
% Bayesian networks, Finite State Machines and Hidden Markov Models can be considered among those.
% Other techniques process the directly as a pattern recognition task, such as  Support Vector Machines, Neural Networks, Dynamic Time Warping, and Bayes and K-means clustering.

% \subsection{Segmentation}
% Describe the different approaches to segmentation.
% Group different viewpoints, e.g. cut-points, change detection, segmentation, etc.


\section{Literature review}
This section will provide a review of the existing literature and research of the different subjects discussed in this thesis.
First the different approaches to mere segmentation of signals is discussed, followed by *** other techniques. ***

\subsection{Segmentation}
One of the first stages in analyzing the sensor data time series is to segment the signal.
The goal is to set cut-points in the signal such that all the data points in between consecutive cut-points have some homogeneous property among them. *** "organizing data into homogeneous groups where the within-group-object similarity is minimized and the between-group-object dissimilarity is maximized." ***
This results in the more abstract notion of change (point) detection.
The general concern is to detect the occurrence and time identification of changes in the signal, often expressed as changes in the probability distribution of the time series.
This literature review will discuss the different types of change detection as applied in the research.
To each applications question about the methods, complexity and usability etc. are asked.
On account of usability, it is desired to have a successful segmentation algorithm with minimal user interaction, e.g. defining thresholds and error rates.
** something about what is considered, e.g. complexity, measurements, e.g. ***

Following the organization of \cite{warren2005clustering}, research can be structured in three groups.
The data being processed determines the classification, which can be the raw data, indirectly via features extracted from the raw data or indirectly via models extracted from the raw data.

One of the more simple and directs methods is to Piecewise Linear Represent the signal, while keeping the approximation error below a certain value, as discussed in \cite{keogh2001online}.
As with many algorithms, PLR can be applied to a batch of or real time stream input data (also known as off-line and on-line analyzes, respectively).
Keogh et al. \cite{keogh2001online} propose a method which combines these different techniques to form a Sliding Window and Bottom-up (SWAB) analyzes.
The algorithm works by first, per window of data points, creating for every two data points a segment.
Neighboring segments are joined together, as long as the approximation error is below the provided value.
This analyzes can be used as a starting point to further analyze the data segments.
Although Keogh et al. apply the SWAB algorithm only direct on the raw data, it is easily imagined how to apply it to extracted features of the signal, e.g. the energy or mean.
In its default application, the method yields little information about each segment; it is merely a linear representation.
The SWAB algorithm works by segmenting parts of the data series by linear approximation while keeping the error below a certain rate.
This rate needs to be user defined (e.g. by an expert), which makes it not possible to apply directly on any signal.
This method only divides the signal into segments, which representations can be processed further to form clusters or related segments.
The complexity of this method is relatively low, $O(Ln)$, where $L$ is the expected segment length and $n$ the number of data points.

The task of segmenting any form of data is made easier when the number of segments is beforehand known.
Many authors apply the well-known \emph{k-means} clustering *** refs needed *** on this type of problems.
An incremental error-minimizing version can determine the optimal number of segments (or actually, clusters in this case).
The proposed method of \cite{himberg2001time}, Global Iterative Replacement, resembles the method of Keogh et al., in the sense that it merges segments.
The algorithm is applied on two different data sets.
The first data sets can be considered as extracted features from sensor data, whilst the second data set works on model properties and thus can give a richer contextual segmentation.
For both types of data sets a cost function is defined, which represents the internal heterogeneity of a segment (e.g. the variance of the data within a segment).
The difference with the method of Keogh et al. is that with GIR the number of segments is known beforehand and during the algorithm this number is, through splits and merges, kept constant.
By running multiple instances of the GIR algorithm with each an increasing number of $k$ segments (bounded by user provided values), the optimal number and location of cut points is determined.

Other approaches form a higher level analyses of the raw data.
As used in \cite{barbivc2004segmenting}, from the field of computer graphics, the dimensionality of the data can be used to distinguish between actions.
Using Principal Component Analyses, Barbi{\v{c}} et al. use the dimensionality required to project the data points on a hyperplane while keeping the error below a certain rate as a measure of similarity.
The error threshold is fixed as a range of three times the standard deviation from the mean of the error.
In an extension of their method, using Probabilistic PCA \cite{tipping1999probabilistic}, the Mahanalobis distance \cite{duda1995pattern} for each frame represents similarity of concurrent motions.
By traversing the Mahanalobis distance as a function of the frames, cut-points are placed on specific points of interest.
*** NOTE to self: thus this method can segment (and group) unknown and new activities? ***
In a third method the authors use a Gaussian Mixture Model *** elaborate on this one [does it segment of direct classify?] ***.
Using this segmenting, and comparing the segments with earlier gathered representations of motions, the PPCA method gets the best results, with precision of 92\% and recall of 95\%.
The test subjects wore 14 sensors on joints of the body and each frame is represented as a 56-dimensional vector.
The test considered seven simple human motions: walking, running, sitting down, forward jumping, climbing, arm stretching and punching.

It is very common the use a higher level of features extracted from the raw data.
The approach of Zhou et al. \cite{zhou2008aligned} maps the data points to a higher dimension by using a kernel function.
The proposed method, Aligned Cluster Analysis, extends kernel $k$-means clustering on this higher dimensional data set.
Using the Dynamic Time Aligned Kernel (DTAK) metric, similarity between segments is measured.
Due to the properties of $k$-means clustering, discovering an unknown number of segments in the data set requires and iterative approach.


*** motifs ***


*** HMM ***

*** Finite mixture models ***

*** Infinite mixture models ***


*****
List of all papers, shortly categorized
\begin{itemize}
  \item ``Discovering characteristic actions from on-body sensor data'' \cite{minnen2006discovering}, cited: 63. Motifs, HHM, DTW, 87\% accuracy. Known motifs.
  \item ``Recognition of human activities using layered hidden Markov models'' \cite{perdikis2008recognition}, cited: 3. HMM, layerd (primitive and abstract actions). Uses vision for workplace-activities. Direct classification
  \item ``Accelerometer-Based Gait Analysis, A survey'', \cite{derawi2010accelerometer}, cited: 4. Compares methods to distinguish walking of normal, fast, slow. Focus on gait, but compares classification methods such as SVM, PCA, KSOM.
  \item ``An Automatic Segmentation Technique in Body Sensor Networks based on Signal Energy'', \cite{guenterberg2009automatic}, cited: 13. Automatic segmenting, adaptive threshold. Pure segmenting, no classification. Nice and clean method? Weakness: single action segmented as multiple. Used multiple sensors.
  \item ``Towards HMM based Human Motion Recognition using MEMS Inertial Sensors'', \cite{shi2009towards}, cited: 13. Uses HHM, Fourier transform for features. 5 fixed activities, trained HMM. Correct rates from 90\% to 100\%. Classification, not just segmentation
  \item ``Change-Point Detection in Time-Series Data by Direct Density-Ratio Estimation'', \cite{kawahara2009change}, cited: 41. Non-parametric approach, online method, no strong model assumptions. Uses multiple datasets, origin referenced. Much follow-up work done.
  \item ``Unsupervised, Dynamic Identification of Physiological and Activity Context in Wearable Computing'', \cite{krause2003unsupervised}, cited: 106(!). Combination of KSOM, iterative K-means clustering, transient states removal (using markov model). On-line algorithm.
  \item ``Activity Recognition using Cell Phone Accelerometers'', \cite{kwapisz2011activity}, cited: 122 (!), 2011. Uses WEKA: decision trees, logistic regression and multilayer neural networks. Results up to 98\% (jogging). Much difficulty with stairs up and down. Single accelerometer. Offline method. Many recent references.
  \item ``Activity recognition from accelerometer data'', \cite{ravi2005activity}, cited: 434 (!), 2005. Compares 18 (offline) classifiers, base level (WEKA) and meta-level. Single device, pelvic region.
  \item ``Activity recognition from user-annotated acceleration data'', \cite{bao2004activity}, cited: 1008 (!!), 2004. Five bi-axial sensors. Decision tables, instance-based learning, C4.5 (trees, highest accuracy 89.30\%) and naive bayes (weka), twenty activities.
  \item ``Using Hierarchical Clustering Methods to Classify Motor Activities of COPD Patients from Wearable Sensor Data'', \cite{sherril2005using}, cited: none, 2005. Uses Linear Discriminant Analysis for cluster classification (using Cluster Quality Index to determine k) and simple rule-based separation for high level ambulatory. Hierarchical Dendogram to merge clusters when similarity to high.
  \item ``Non-Parametric Bayesian Human Motion Recognition Using a Single MEMS Tri-Axial Accelerometer'', \cite{ahmed2012non}, cited: none, 2012. Recognizes the number of human activities, single sensor on the chest. No training data. Infinite Gaussian Mixture Model, collapsed Gibbs sampler. Compares with parametric Fuzzy C-mean (data point belongs to multiple clusters), unsupervised K-means, non-parametric mean-shift. Outperforms all significantly, high hit rate and low false alarms.
  \item ``An Online Algorithm for Segmenting Time Series'', \cite{keogh2001online}, cited: 487, 2001. Reviews algorithms to get a piecewise linear representation, proposes a novel sliding-window and bottom up approach, on-line. Mere segmentation. No classification; only approximation of signal. (Dataset available).
  \item ``Segmenting Motion Capture Data into Distinct Behaviors'', \cite{barbivc2004segmenting}, cited: 242, 2004. On-line methods: cut-points on increased intrinsic dimensionality, distribution of poses is observed to change. Batch: cut when consecutive frames belong to different Gaussian mixture models. Fixed fourteen motions, compared with manual segmentation. Uses PCA and Probabilistic PCA (models the non-pc subspaces as noise). PPCA is the best. (paper anne)
  \item ``Aligned Cluster Analysis for Temporal Segmentation of Human Motion'', \cite{zhou2008aligned}, cited: 54, 2008. Uses extension on kernel k-means clustering and Dynamic Time Alignment Kernel (kernel of DTW) for temporal invariance, robust temporal matching metric. Coordinate descent algorithm solves ACA. Fixed number of clusters, trapped in local minima. (paper anne)
  \item ``Bayesian Nonparametric Methods for Learning Markov Switching Processes'', \cite{fox2010bayesian}, cited: 10, 2010. Uses HMM for state-space model for segmentation, Markov Jump Linear systems. Unbounded number of Markov modes (parameters). Number of models is fixed, though? (paper anne).
  \item ``Layered Representations for Human Activity Recognition'', \cite{oliver2002layered}, cited: 215, 2002. Layers of Hidden Markov Models HMM, multiple levels of granularity (Based on intuition) and context. Less retraining, only lower models. Classified also.
  \item ``Time series segmentation for context recognition in mobile devices'', \cite{himberg2001time}, cited: 151, 2001. Splits and merges segments, while keeping k constant using cost function on segments for internal heterogeneity. Multiple instances determine number of k.
  \item ``A practical approach to recognizing physical activities'', \cite{lester2006practical}, cited: 259, 2006. Uses method of \cite{lester2005hybrid}, activity classification algorithm. Selects most useful features and then recognizes walking, sitting, etc. First layer static classifier on features or data (energy, mean, variance, correlation, etc), then a layer of HMM to estimate activity. All offline. Shows trained model is robust to location of wearing on body.
  \item ``A hybrid discriminative/generative approach for modeling human activities'', \cite{lester2005hybrid}, cited: 252, 2005. Used in method above. Combines boosting to select and reduce useful features and learn static classifiers with HMM to capture regularities and smooth activities (quick switching is unlikely). Single sensor, multiple measures (accelerometer, audio, etc).
  \item ``Using acceleration measurements for activity recognition: An effective learning algorithm for constructing neural classifiers'', \cite{yang2008using}, cited: 67, 2008. Separates dynamic from static activities. Uses multilayer feedforward neural networks to generate complex discriminating surfaces as activity classifiers. Feature subset selection approach is developed. Neural pre-classifier with constant threshold criterion. Uses Common Principal Component Analysis. Recognizes eight activities with 95\% overall accuracy.
  \item ``Single-accelerometer-based daily physical activity classification'', \cite{long2009single}, cited: 46, 2009. Uses Naive Bayes classifier, sensor worn on wrist. Five activities. PCA to reduce dimensions and create independence for NB. Comparable results as Decision Trees, but with flexibility to add activities.
  \item ``Distributed Continuous Action Recognition Using a Hidden Markov Model in Body Sensor Networks''. Single HMM, sensor network cluster movements, HMM constructs continuous actions using postures and actions.*** explain more on this one ***.
\end{itemize}





*** Elaborate on measures, e.g. precision, recall, confusion matrix etc.  ***
*** Precision is defined as the ratio of reported correct cuts versus the total number of reported cuts. Recall is defined as the ratio of reported correct cuts versus the total number of correct cuts. The closer precision and recall are to 1, the more accurate the algorithm is. ***